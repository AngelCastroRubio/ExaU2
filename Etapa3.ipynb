{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHUcinevxszxGDIeTVpLh0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelCastroRubio/ExaU2/blob/main/Etapa3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 1, correspondiente a la Importación de datos y módulos básicos, Visualización y Análisis Exploratorio del Conjunto de Datos y a las Estadísticas de Resumen y Coeficiente de Variación"
      ],
      "metadata": {
        "id": "9_ZsSJiMH3xM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqXlugyIHvzr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#----Visualización y Análisis Exploratorio del Conjunto de Datos----\n",
        "# Carga del conjunto de datos\n",
        "data = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
        "\n",
        "# Visualización de las primeras filas del conjunto de datos\n",
        "print(data.head())\n",
        "\n",
        "# Verificación de tipos de datos\n",
        "print(data.dtypes)\n",
        "\n",
        "# Análisis de valores únicos\n",
        "print(data.nunique())\n",
        "\n",
        "#----Estadísticas de Resumen y Coeficiente de Variación----\n",
        "# Estadísticas descriptivas\n",
        "print(data.describe())\n",
        "\n",
        "# Seleccionar solo columnas numéricas\n",
        "data_numeric = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calcular la desviación estándar y el coeficiente de variación\n",
        "std = data_numeric.std()\n",
        "mean = data_numeric.mean()\n",
        "cv = std / mean\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Desviacion estandar:\")\n",
        "print(std)\n",
        "print(\"\\nCoeficiente de variacion:\")\n",
        "print(cv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 2: Preparación de los Datos. Se siguen los siguientes pasos: Eliminación de Variables Redundantes, Comprobación e Imputación de Valores Perdidos, Identificación y Limitación de Valores Atípicos, Codificación de Características, Importancia de las Características y Eliminación de la Multicolinealidad"
      ],
      "metadata": {
        "id": "h9EaJCe_t2yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos la variable ID del DataSet\n",
        "data.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Realizamos la Comprobación e Imputación a BMI usando la mediana\n",
        "median_bmi = data['bmi'].median()\n",
        "data.loc[:, 'bmi'] = data['bmi'].fillna(median_bmi)\n",
        "\n",
        "# Limitamos los valores atípicos de nuestra muestra con los percentiles\n",
        "q_low = data['avg_glucose_level'].quantile(0.05)\n",
        "q_hi = data['avg_glucose_level'].quantile(0.95)\n",
        "data = data[(data['avg_glucose_level'] >= q_low) & (data['avg_glucose_level'] <= q_hi)]\n",
        "\n",
        "q_low = data['bmi'].quantile(0.05)\n",
        "q_hi = data['bmi'].quantile(0.95)\n",
        "data = data[(data['bmi'] >= q_low) & (data['bmi'] <= q_hi)]\n",
        "\n",
        "# Codificamos las caracteristicas actuales y las usamos numericamente\n",
        "data_encoded = pd.get_dummies(data)\n",
        "print(data_encoded.columns)\n",
        "\n",
        "# Renombrar la columna 'stroke' a 'ictus'\n",
        "data_encoded.rename(columns={'stroke': 'ictus'}, inplace=True)\n",
        "\n",
        "# Eliminar la columna 'ictus' del conjunto de datos\n",
        "X = data_encoded.drop('ictus', axis=1)\n",
        "\n",
        "# Importancia de las características\n",
        "from xgboost import XGBClassifier\n",
        "X = data_encoded.drop('ictus', axis=1)\n",
        "y = data_encoded['ictus']\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "feature_importances = model.feature_importances_\n",
        "print(X.columns)\n",
        "\n",
        "# Eliminación de la multicolinealidad\n",
        "corr_matrix = X.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "X = X.drop(to_drop, axis=1)\n",
        "print(X.columns)\n",
        "\n",
        "# Mostrar las primeras filas del conjunto de datos con la nueva columna 'ictus'\n",
        "print(X.head())"
      ],
      "metadata": {
        "id": "dUERBr45t42G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 3"
      ],
      "metadata": {
        "id": "jHgrnNsr49cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba (70% entrenamiento, 30% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Entrenar modelo de regresión logística\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calcular precisión\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Crear DataFrame con los resultados\n",
        "results = pd.DataFrame({\n",
        "    'Conjunto de Datos': ['Entrenamiento', 'Prueba'],\n",
        "    'Precisión': [accuracy_train, accuracy_test]\n",
        "})\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(results)"
      ],
      "metadata": {
        "id": "SHquoYojHzdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}