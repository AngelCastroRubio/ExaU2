{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPcxxePgDq+bq2rWWhGmJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelCastroRubio/ExaU2/blob/main/Etapa%204.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 1, correspondiente a la Importación de datos y módulos básicos, Visualización y Análisis Exploratorio del Conjunto de Datos y a las Estadísticas de Resumen y Coeficiente de Variación"
      ],
      "metadata": {
        "id": "9_ZsSJiMH3xM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqXlugyIHvzr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#----Visualización y Análisis Exploratorio del Conjunto de Datos----\n",
        "# Carga del conjunto de datos\n",
        "data = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
        "\n",
        "# Visualización de las primeras filas del conjunto de datos\n",
        "print(data.head())\n",
        "\n",
        "# Verificación de tipos de datos\n",
        "print(data.dtypes)\n",
        "\n",
        "# Análisis de valores únicos\n",
        "print(data.nunique())\n",
        "\n",
        "#----Estadísticas de Resumen y Coeficiente de Variación----\n",
        "# Estadísticas descriptivas\n",
        "print(data.describe())\n",
        "\n",
        "# Seleccionar solo columnas numéricas\n",
        "data_numeric = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calcular la desviación estándar y el coeficiente de variación\n",
        "std = data_numeric.std()\n",
        "mean = data_numeric.mean()\n",
        "cv = std / mean\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Desviacion estandar:\")\n",
        "print(std)\n",
        "print(\"\\nCoeficiente de variacion:\")\n",
        "print(cv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 2: Preparación de los Datos. Se siguen los siguientes pasos: Eliminación de Variables Redundantes, Comprobación e Imputación de Valores Perdidos, Identificación y Limitación de Valores Atípicos, Codificación de Características, Importancia de las Características y Eliminación de la Multicolinealidad"
      ],
      "metadata": {
        "id": "h9EaJCe_t2yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos la variable ID del DataSet\n",
        "data.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Realizamos la Comprobación e Imputación a BMI usando la mediana\n",
        "median_bmi = data['bmi'].median()\n",
        "data.loc[:, 'bmi'] = data['bmi'].fillna(median_bmi)\n",
        "\n",
        "# Limitamos los valores atípicos de nuestra muestra con los percentiles\n",
        "q_low = data['avg_glucose_level'].quantile(0.05)\n",
        "q_hi = data['avg_glucose_level'].quantile(0.95)\n",
        "data = data[(data['avg_glucose_level'] >= q_low) & (data['avg_glucose_level'] <= q_hi)]\n",
        "\n",
        "q_low = data['bmi'].quantile(0.05)\n",
        "q_hi = data['bmi'].quantile(0.95)\n",
        "data = data[(data['bmi'] >= q_low) & (data['bmi'] <= q_hi)]\n",
        "\n",
        "# Codificamos las caracteristicas actuales y las usamos numericamente\n",
        "data_encoded = pd.get_dummies(data)\n",
        "print(data_encoded.columns)\n",
        "\n",
        "# Renombrar la columna 'stroke' a 'ictus'\n",
        "data_encoded.rename(columns={'stroke': 'ictus'}, inplace=True)\n",
        "\n",
        "# Eliminar la columna 'ictus' del conjunto de datos\n",
        "X = data_encoded.drop('ictus', axis=1)\n",
        "\n",
        "# Importancia de las características\n",
        "from xgboost import XGBClassifier\n",
        "X = data_encoded.drop('ictus', axis=1)\n",
        "y = data_encoded['ictus']\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "feature_importances = model.feature_importances_\n",
        "print(X.columns)\n",
        "\n",
        "# Eliminación de la multicolinealidad\n",
        "corr_matrix = X.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "X = X.drop(to_drop, axis=1)\n",
        "print(X.columns)\n",
        "\n",
        "# Mostrar las primeras filas del conjunto de datos con la nueva columna 'ictus'\n",
        "print(X.head())"
      ],
      "metadata": {
        "id": "dUERBr45t42G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 3"
      ],
      "metadata": {
        "id": "jHgrnNsr49cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba (70% entrenamiento, 30% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Entrenar modelo de regresión logística\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calcular precisión\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Crear DataFrame con los resultados\n",
        "results = pd.DataFrame({\n",
        "    'Conjunto de Datos': ['Entrenamiento', 'Prueba'],\n",
        "    'Precisión': [accuracy_train, accuracy_test]\n",
        "})\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(results)"
      ],
      "metadata": {
        "id": "SHquoYojHzdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "39ca21e1-66e7-4cef-ee9b-c42607238df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-165e155c477d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dividir el conjunto de datos en entrenamiento y prueba (70% entrenamiento, 30% prueba)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Entrenar modelo de regresión logística\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 4"
      ],
      "metadata": {
        "id": "K-C2TJPzI7F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------Etapa 4: Evaluacion de modelos------------------------------\n",
        "# Métricas de rendimiento para los datos de entrenamiento\n",
        "y_pred_train = model.predict(X_train)\n",
        "precision_train = precision_score(y_train, y_pred_train)\n",
        "recall_train = recall_score(y_train, y_pred_train)\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "f1_train = f1_score(y_train, y_pred_train)\n",
        "balanced_accuracy_train = balanced_accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Tasa de verdaderos positivos (Recall) para los datos de entrenamiento\n",
        "tp_train = ((y_train == 1) & (y_pred_train == 1)).sum()\n",
        "fn_train = ((y_train == 1) & (y_pred_train == 0)).sum()\n",
        "tpr_train = tp_train / (tp_train + fn_train)\n",
        "\n",
        "# Tasa de verdaderos negativos (Especificidad) para los datos de entrenamiento\n",
        "tn_train = ((y_train == 0) & (y_pred_train == 0)).sum()\n",
        "fp_train = ((y_train == 0) & (y_pred_train == 1)).sum()\n",
        "tnr_train = tn_train / (tn_train + fp_train)\n",
        "\n",
        "# Métricas de rendimiento para los datos de prueba\n",
        "y_pred_test = model.predict(X_test)\n",
        "precision_test = precision_score(y_test, y_pred_test, zero_division=0)\n",
        "recall_test = recall_score(y_test, y_pred_test)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "f1_test = f1_score(y_test, y_pred_test)\n",
        "balanced_accuracy_test = balanced_accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Matriz de confusión para los datos de prueba\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\nMatriz de confusión para los datos de prueba:\")\n",
        "print(conf_matrix_test)\n",
        "\n",
        "# Análisis de si el modelo está sobreajustado\n",
        "if recall_train > recall_test:\n",
        "    print(\"\\nEl modelo está sobreajustado (overfitting) ya que el recall en los datos de entrenamiento es mayor que en los datos de prueba.\")\n",
        "else:\n",
        "    print(\"\\nEl modelo no está sobreajustado (overfitting).\")\n",
        "\n",
        "# Tasa de verdaderos positivos (Recall) para los datos de prueba\n",
        "tp_test = ((y_test == 1) & (y_pred_test == 1)).sum()\n",
        "fn_test = ((y_test == 1) & (y_pred_test == 0)).sum()\n",
        "tpr_test = tp_test / (tp_test + fn_test)\n",
        "\n",
        "# Tasa de verdaderos negativos (Especificidad) para los datos de prueba\n",
        "tn_test = ((y_test == 0) & (y_pred_test == 0)).sum()\n",
        "fp_test = ((y_test == 0) & (y_pred_test == 1)).sum()\n",
        "tnr_test = tn_test / (tn_test + fp_test)\n",
        "\n",
        "print(\"Métricas de rendimiento para los datos de entrenamiento:\")\n",
        "print(f\"Precisión: {precision_train}\")\n",
        "print(f\"Recall (Tasa de verdaderos positivos): {recall_train}\")\n",
        "print(f\"Especificidad (Tasa de verdaderos negativos): {tnr_train}\")\n",
        "print(f\"Precisión equilibrada: {balanced_accuracy_train}\")\n",
        "print(f\"Puntuación F1: {f1_train}\")\n",
        "\n",
        "print(\"\\nMétricas de rendimiento para los datos de prueba:\")\n",
        "print(f\"Precisión: {precision_test}\")\n",
        "print(f\"Recall (Tasa de verdaderos positivos): {recall_test}\")\n",
        "print(f\"Especificidad (Tasa de verdaderos negativos): {tnr_test}\")\n",
        "print(f\"Precisión equilibrada: {balanced_accuracy_test}\")\n",
        "print(f\"Puntuación F1: {f1_test}\")\n",
        "\n",
        "# Calcular probabilidades predichas\n",
        "y_prob_test = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob_test)\n",
        "\n",
        "# Encontrar el umbral óptimo\n",
        "optimal_threshold_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_threshold_idx]\n",
        "\n",
        "# Convertir probabilidades predichas en clases binarias con el umbral optimo\n",
        "y_pred_test_optimal = (y_prob_test >= optimal_threshold).astype(int)\n",
        "\n",
        "# Calcular métricas de rendimiento con el umbral óptimo\n",
        "precision_test_optimal = precision_score(y_test, y_pred_test_optimal)\n",
        "recall_test_optimal = recall_score(y_test, y_pred_test_optimal)\n",
        "accuracy_test_optimal = accuracy_score(y_test, y_pred_test_optimal)\n",
        "f1_test_optimal = f1_score(y_test, y_pred_test_optimal)\n",
        "balanced_accuracy_test_optimal = balanced_accuracy_score(y_test, y_pred_test_optimal)\n",
        "\n",
        "# Comparar los resultados con el umbral por defecto\n",
        "print(\"\\nMétricas de rendimiento para los datos de prueba con umbral optimo:\")\n",
        "print(f\"Precision: {precision_test_optimal}\")\n",
        "print(f\"Recall (Tasa de verdaderos positivos): {recall_test_optimal}\")\n",
        "print(f\"Precision equilibrada: {balanced_accuracy_test_optimal}\")\n",
        "print(f\"Puntuacion F1: {f1_test_optimal}\")\n",
        "\n",
        "# Comparar con los resultados anteriores\n",
        "print(\"\\nComparacion con umbral por defecto:\")\n",
        "print(f\"Precision: {precision_test}\")\n",
        "print(f\"Recall (Tasa de verdaderos positivos): {recall_test}\")\n",
        "print(f\"Precision equilibrada: {balanced_accuracy_test}\")\n",
        "print(f\"Puntuacion F1: {f1_test}\")"
      ],
      "metadata": {
        "id": "fNwSKhPtI-6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}